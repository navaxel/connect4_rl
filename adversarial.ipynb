{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaggle-environments\n",
    "#!pip install chardet\n",
    "#!pip install charset-normalizer\n",
    "#!pip install gym\n",
    "#!pip install tqdm\n",
    "#!pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment lux_ai_s2 failed: No module named 'vec_noise'\n"
     ]
    }
   ],
   "source": [
    "from kaggle_environments import make\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "\n",
    "from Scripts.MCTS import agent_mcts\n",
    "from Scripts.Deep_Q_Learning import DQN\n",
    "import matplotlib.pyplot as plt\n",
    "#from Scripts.training import train_agent,load_agent, train_adversial_agent\n",
    "\n",
    "from Scripts.test_model import test_agent, new_testing\n",
    "\n",
    "from Scripts.training import train_agent,save_agent,load_agent\n",
    "from Scripts.new_training import train_adversial_agent\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Initialisating the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 7\n",
    "rows = 6\n",
    "env = make(\"connectx\", configuration={\"rows\":rows, \"columns\":cols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL_agent1 = False\n",
    "LOAD_MODEL_agent2 = False\n",
    "\n",
    "\n",
    "PATH_TO_LOAD = \"models/\"\n",
    "NAME_AGENT_1 = \"1v2_ep20.pt\"\n",
    "NAME_AGENT_2 = \"2v1_ep20.pt\"\n",
    "\n",
    "\n",
    "if(LOAD_MODEL_agent1):\n",
    "    agent1 = load_agent(PATH_TO_LOAD+NAME_AGENT_1)\n",
    "else :\n",
    "    agent1 = DQN()\n",
    "\n",
    "\n",
    "if(LOAD_MODEL_agent2):\n",
    "    agent2 = load_agent(PATH_TO_LOAD+NAME_AGENT_2)\n",
    "else:\n",
    "    agent2 = DQN()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training against Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent1 = train_agent(env,agent1,\"random\",n_player=1,epochs=RANDOM_EPOCHS,display_info=True, save=False)\n",
    "#agent2 = train_agent(env,agent2,\"random\",n_player=2,epochs=RANDOM_EPOCHS,display_info=True, save=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADVERSARIAL_EPOCHS = 10000\n",
    "NB_SWITCH = 10\n",
    "\n",
    "FOLLOW_TRAINING = True\n",
    "NB_GAMES_TEST = 100\n",
    "\n",
    "history_random = []\n",
    "history_MCTS = []\n",
    "history_negamax = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NB_SWITCH):\n",
    "    agent1 = train_adversial_agent(env,agent1, agent2,n_player=1,epochs=ADVERSARIAL_EPOCHS,display_info=True)\n",
    "    agent2 = train_adversial_agent(env,agent2, agent1 ,n_player=2,epochs=ADVERSARIAL_EPOCHS,display_info=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FOLLOW_TRAINING:\n",
    "    current_history_random = new_testing(env,agent1,env.agents[\"random\"],n_player=1,nb_games=NB_GAMES_TEST)\n",
    "    #current_history_MCTS = new_testing(env,agent1,agent_mcts,n_player=1,nb_games=NB_GAMES_TEST)\n",
    "    current_history_negamax = new_testing(env,agent1,env.agents[\"negamax\"],n_player =1, nb_games=NB_GAMES_TEST)\n",
    "\n",
    "    history_random.append(current_history_random[1]/NB_GAMES_TEST*100)\n",
    "    #history_MCTS.append(current_history_MCTS[1]/NB_GAMES_TEST*100)\n",
    "    history_negamax.append(current_history_negamax[1]/NB_GAMES_TEST*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random :  {1: 66, -1: 33, None: 0, 0: 0}\n",
      "negamax : {1: 4, -1: 95, None: 0, 0: 0}\n"
     ]
    }
   ],
   "source": [
    "print('random : ',current_history_random)\n",
    "print('negamax :',current_history_negamax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if FOLLOW_TRAINING:\n",
    "    plt.plot(history_random)\n",
    "    #plt.plot(history_MCTS)\n",
    "    plt.plot(history_negamax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Testing Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_GAMES_TEST = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Against random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DQN.choose_action() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history_random \u001b[39m=\u001b[39m test_agent(env,agent1,\u001b[39m\"\u001b[39;49m\u001b[39mrandom\u001b[39;49m\u001b[39m\"\u001b[39;49m,n_player\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,nb_games\u001b[39m=\u001b[39;49mNB_GAMES_TEST)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(history_random)\n",
      "File \u001b[0;32m~/Desktop/3A/INF581 RL/Projet/tests/Scripts/test_model.py:25\u001b[0m, in \u001b[0;36mtest_agent\u001b[0;34m(env, agent_to_test, agent_against, n_player, nb_games, rows, cols)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     j\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m---> 25\u001b[0m     trained_action \u001b[39m=\u001b[39m agent_to_test\u001b[39m.\u001b[39;49mchoose_action(n_player, state, env)\n\u001b[1;32m     26\u001b[0m     \u001b[39mif\u001b[39;00m n_player \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     27\u001b[0m         intermediary_state \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(env\u001b[39m.\u001b[39mstep([trained_action, \u001b[39mNone\u001b[39;00m])[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mobservation\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mboard\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m1\u001b[39m, rows, cols])\n",
      "\u001b[0;31mTypeError\u001b[0m: DQN.choose_action() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "history_random = test_agent(env,agent1,\"random\",n_player=1,nb_games=NB_GAMES_TEST)\n",
    "print(history_random)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Against MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_MCTS = test_agent(env,agent1,agent_mcts,n_player=1,nb_games=NB_GAMES_TEST)\n",
    "plt.plot(history_MCTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Against MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_negamax = test_agent(env,agent1,\"negamax\",n_player =1, nb_games=NB_GAMES_TEST)\n",
    "plt.plot(history_negamax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Saving Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True\n",
    "PATH_TO_SAVE = \"models/\"\n",
    "\n",
    "NAME1 = \"1v2_ep\"+ str(NB_SWITCH*ADVERSARIAL_EPOCHS)\n",
    "NAME2 = \"2v1_ep\"+ str(NB_SWITCH*ADVERSARIAL_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE :\n",
    "    save_agent(agent1, path_to_save=PATH_TO_SAVE, name=NAME1, epochs=NB_SWITCH*ADVERSARIAL_EPOCHS)\n",
    "    save_agent(agent2, path_to_save=PATH_TO_SAVE, name=NAME2, epochs=NB_SWITCH*ADVERSARIAL_EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Testing efficiency of the training against rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "NB_GAMES_TEST = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = DQN()\n",
    "\n",
    "for i in range(1):\n",
    "    agent1 = train_agent(env,agent1,\"random\",n_player=1,epoch=100,display_info=False)\n",
    "    current_history = test_agent(env,agent1,\"random\",n_player=1,nb_games=NB_GAMES_TEST)\n",
    "    print(current_history)\n",
    "    history.append(current_history[1]/nb_games_test * 100)\n",
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "plt.title(\"Neural Network vs Random Player - Trained only against the random player\")\n",
    "plt.xlabel(\"Training time 100's of games\")\n",
    "plt.ylabel(\"Wins per 100 games in testing phase\")\n",
    "history.insert(0,50)\n",
    "plt.plot(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8aa6b6d7fc0352aec01852ba3878270997e10287822bc8d006a87177ddd021e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
